{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8rc1"
    },
    "colab": {
      "name": "nlp_into_l1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezy5D-72aGlJ",
        "outputId": "12e89a08-19d1-4494-8248-2e60dd44274a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "# 1. NLTK\n",
        "# imports & donwloads\n",
        "import nltk\n",
        "nltk.download([\"punkt\", \"wordnet\", \"averaged_perceptron_tagger\"])\n",
        "\n",
        "\"\"\"\n",
        "Punkt Sentence Tokenizer. \n",
        "This tokenizer divides a text into a list of sentences, \n",
        "by using an unsupervised algorithm to build a model for abbreviation words, \n",
        "collocations, and words that start sentences. \n",
        "\n",
        "WordNet is a lexical database for the English language, \n",
        "which was created by Princeton, and is part of the NLTK corpus. \n",
        "You can use WordNet alongside the NLTK module to find \n",
        "the meanings of words, synonyms, antonyms, and more.\n",
        "\n",
        "Averaged_perceptron_tagger is used for tagging words with their parts of speech (POS)\n",
        "\"\"\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nPunkt Sentence Tokenizer. \\nThis tokenizer divides a text into a list of sentences, \\nby using an unsupervised algorithm to build a model for abbreviation words, \\ncollocations, and words that start sentences. \\n\\nWordNet is a lexical database for the English language, \\nwhich was created by Princeton, and is part of the NLTK corpus. \\nYou can use WordNet alongside the NLTK module to find \\nthe meanings of words, synonyms, antonyms, and more.\\n\\nAveraged_perceptron_tagger is used for tagging words with their parts of speech (POS)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6Hj33POankf",
        "outputId": "8bc0140d-b766-4294-8de6-60b9f1d982e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "import this\n",
        "import codecs\n",
        "\n",
        "zen_of_python = codecs.encode(this.s, \"rot13\")\n",
        "zen_of_python"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"The Zen of Python, by Tim Peters\\n\\nBeautiful is better than ugly.\\nExplicit is better than implicit.\\nSimple is better than complex.\\nComplex is better than complicated.\\nFlat is better than nested.\\nSparse is better than dense.\\nReadability counts.\\nSpecial cases aren't special enough to break the rules.\\nAlthough practicality beats purity.\\nErrors should never pass silently.\\nUnless explicitly silenced.\\nIn the face of ambiguity, refuse the temptation to guess.\\nThere should be one-- and preferably only one --obvious way to do it.\\nAlthough that way may not be obvious at first unless you're Dutch.\\nNow is better than never.\\nAlthough never is often better than *right* now.\\nIf the implementation is hard to explain, it's a bad idea.\\nIf the implementation is easy to explain, it may be a good idea.\\nNamespaces are one honking great idea -- let's do more of those!\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKMhwcI8cCnr"
      },
      "source": [
        "russian_text = \"\"\"Граф Лев Николаевич Толсто́й[К 1] (28 августа [9 сентября] 1828, Ясная Поляна, Тульская губерния, Российская \n",
        "империя — 7 [20] ноября 1910, станция Астапово, Рязанская губерния, Российская империя) — один из наиболее известных русских \n",
        "писателей и мыслителей, один из величайших писателей-романистов мира[4]. Участник обороны Севастополя. Просветитель, публицист, \n",
        "религиозный мыслитель, его авторитетное мнение послужило причиной возникновения нового религиозно-нравственного течения — \n",
        "толстовства. За свои взгляды был отлучен от церкви. Член-корреспондент Императорской Академии наук (1873), почётный академик \n",
        "по разряду изящной словесности (1900)[5]. Был номинирован на Нобелевскую премию по литературе (1902, 1903, 1904, 1905). \n",
        "Впоследствии отказался от дальнейшей номинации.\n",
        "\n",
        "Писатель, ещё при жизни признанный главой русской литературы[6]. Творчество Льва Толстого ознаменовало новый этап в русском и \n",
        "мировом реализме, выступив мостом между классическим романом XIX века и литературой XX века. Лев Толстой оказал сильное влияние \n",
        "на эволюцию европейского гуманизма, а также на развитие реалистических традиций в мировой литературе. Произведения Льва \n",
        "Толстого многократно экранизировались и инсценировались в СССР и за рубежом; его пьесы ставились на сценах всего мира[6]. Лев \n",
        "Толстой был самым издаваемым в СССР писателем за 1918—1986 годы: общий тираж 3199 изданий составил 436,261 млн экземпляров[7].\n",
        "\n",
        "Наиболее известны такие произведения Толстого, как романы «Война и мир», «Анна Каренина», «Воскресение», \n",
        "автобиографическая[8][6] трилогия «Детство», «Отрочество», «Юность»[К 2], повести «Казаки», «Смерть Ивана Ильича», «Крейцерова \n",
        "соната», «Отец Сергий», «Хаджи-Мурат», цикл очерков «Севастопольские рассказы», драмы «Живой труп», «Плоды просвещения» и \n",
        "«Власть тьмы», автобиографические религиозно-философские произведения «Исповедь» и «В чём моя вера?» и др.\n",
        "\"\"\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NK_Q_rTcQ-L"
      },
      "source": [
        "# 2. Tokenization\n",
        "# Tokenization is a process of splitting text to tokens. Let's split the text sentencewise.\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSOPkuXudPwM",
        "outputId": "83cad25b-b18c-47cd-eb15-fa2cb8cab167",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokens = sent_tokenize(zen_of_python)\n",
        "print(tokens)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The Zen of Python, by Tim Peters\\n\\nBeautiful is better than ugly.', 'Explicit is better than implicit.', 'Simple is better than complex.', 'Complex is better than complicated.', 'Flat is better than nested.', 'Sparse is better than dense.', 'Readability counts.', \"Special cases aren't special enough to break the rules.\", 'Although practicality beats purity.', 'Errors should never pass silently.', 'Unless explicitly silenced.', 'In the face of ambiguity, refuse the temptation to guess.', 'There should be one-- and preferably only one --obvious way to do it.', \"Although that way may not be obvious at first unless you're Dutch.\", 'Now is better than never.', 'Although never is often better than *right* now.', \"If the implementation is hard to explain, it's a bad idea.\", 'If the implementation is easy to explain, it may be a good idea.', \"Namespaces are one honking great idea -- let's do more of those!\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8H24M4QdVB0",
        "outputId": "4e56aa47-5111-4e2b-a049-8776d376d5ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Then, we split it wordwise.\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokens = word_tokenize(zen_of_python)\n",
        "print(tokens)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'Zen', 'of', 'Python', ',', 'by', 'Tim', 'Peters', 'Beautiful', 'is', 'better', 'than', 'ugly', '.', 'Explicit', 'is', 'better', 'than', 'implicit', '.', 'Simple', 'is', 'better', 'than', 'complex', '.', 'Complex', 'is', 'better', 'than', 'complicated', '.', 'Flat', 'is', 'better', 'than', 'nested', '.', 'Sparse', 'is', 'better', 'than', 'dense', '.', 'Readability', 'counts', '.', 'Special', 'cases', 'are', \"n't\", 'special', 'enough', 'to', 'break', 'the', 'rules', '.', 'Although', 'practicality', 'beats', 'purity', '.', 'Errors', 'should', 'never', 'pass', 'silently', '.', 'Unless', 'explicitly', 'silenced', '.', 'In', 'the', 'face', 'of', 'ambiguity', ',', 'refuse', 'the', 'temptation', 'to', 'guess', '.', 'There', 'should', 'be', 'one', '--', 'and', 'preferably', 'only', 'one', '--', 'obvious', 'way', 'to', 'do', 'it', '.', 'Although', 'that', 'way', 'may', 'not', 'be', 'obvious', 'at', 'first', 'unless', 'you', \"'re\", 'Dutch', '.', 'Now', 'is', 'better', 'than', 'never', '.', 'Although', 'never', 'is', 'often', 'better', 'than', '*right*', 'now', '.', 'If', 'the', 'implementation', 'is', 'hard', 'to', 'explain', ',', 'it', \"'s\", 'a', 'bad', 'idea', '.', 'If', 'the', 'implementation', 'is', 'easy', 'to', 'explain', ',', 'it', 'may', 'be', 'a', 'good', 'idea', '.', 'Namespaces', 'are', 'one', 'honking', 'great', 'idea', '--', 'let', \"'s\", 'do', 'more', 'of', 'those', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDNHu1nSdu61",
        "outputId": "027d0d73-35b2-45e3-dcf7-e2fedc213148",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Get the most common word in the text\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "dist = FreqDist(tokens)\n",
        "dist.most_common(10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('.', 18),\n",
              " ('is', 10),\n",
              " ('better', 8),\n",
              " ('than', 8),\n",
              " ('to', 5),\n",
              " ('the', 5),\n",
              " (',', 4),\n",
              " ('of', 3),\n",
              " ('Although', 3),\n",
              " ('never', 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md1K41yLeTUW",
        "outputId": "3c856009-fa80-4061-9e0a-88afcc1901c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# install Russian tokenizer razdel is similar to nltk, since nltk does not have Russian language.\n",
        "!pip install razdel"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting razdel\n",
            "  Downloading https://files.pythonhosted.org/packages/15/2c/664223a3924aa6e70479f7d37220b3a658765b9cfe760b4af7ffdc50d38f/razdel-0.5.0-py3-none-any.whl\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPQeMXGVesrW",
        "outputId": "e7e6be1c-6471-420a-83ad-16c1a6872634",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from razdel import sentenize, tokenize\n",
        "\n",
        "text_generator = sentenize(russian_text)\n",
        "print(next(text_generator))\n",
        "print(next(text_generator))\n",
        "\n",
        "list(tokenize(russian_text))[:20]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Substring(0, 308, 'Граф Лев Николаевич Толсто́й[К 1] (28 августа [9 сентября] 1828, Ясная Поляна, Тульская губерния, Российская \\nимперия — 7 [20] ноября 1910, станция Астапово, Рязанская губерния, Российская империя) — один из наиболее известных русских \\nписателей и мыслителей, один из величайших писателей-романистов мира[4].')\n",
            "Substring(309, 338, 'Участник обороны Севастополя.')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Substring(0, 4, 'Граф'),\n",
              " Substring(5, 8, 'Лев'),\n",
              " Substring(9, 19, 'Николаевич'),\n",
              " Substring(20, 28, 'Толсто́й'),\n",
              " Substring(28, 29, '['),\n",
              " Substring(29, 30, 'К'),\n",
              " Substring(31, 32, '1'),\n",
              " Substring(32, 33, ']'),\n",
              " Substring(34, 35, '('),\n",
              " Substring(35, 37, '28'),\n",
              " Substring(38, 45, 'августа'),\n",
              " Substring(46, 47, '['),\n",
              " Substring(47, 48, '9'),\n",
              " Substring(49, 57, 'сентября'),\n",
              " Substring(57, 58, ']'),\n",
              " Substring(59, 63, '1828'),\n",
              " Substring(63, 64, ','),\n",
              " Substring(65, 70, 'Ясная'),\n",
              " Substring(71, 77, 'Поляна'),\n",
              " Substring(77, 78, ',')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiuJUOfyfB93",
        "outputId": "6976f134-27ed-4e59-cc6e-563fbd7caacd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 3. Stemming \n",
        "\"\"\"\n",
        "Usually, we want to preprocess text before performing analysis. \n",
        "Normalization is a preprocessing technique that helps simplify analysis. \n",
        "Stemming is a type of normalization. \n",
        "The following code shows us how to use Porter stemming method to get basic for words.\n",
        "\"\"\"\n",
        "from nltk.stem import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "[porter.stem(word) for word, freq in dist.most_common(20)]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.',\n",
              " 'is',\n",
              " 'better',\n",
              " 'than',\n",
              " 'to',\n",
              " 'the',\n",
              " ',',\n",
              " 'of',\n",
              " 'although',\n",
              " 'never',\n",
              " 'be',\n",
              " 'one',\n",
              " '--',\n",
              " 'it',\n",
              " 'idea',\n",
              " 'are',\n",
              " 'should',\n",
              " 'obviou',\n",
              " 'way',\n",
              " 'do']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dzz3ElRf19Y",
        "outputId": "d882d60d-238f-44e6-d3a0-587dfdfc776b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "[porter.stem(word) for word in [\"words\", \"stemming\", \"understood\", \"helps\", \"finished\"]]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['word', 'stem', 'understood', 'help', 'finish']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAe3Lkgrf5Zw",
        "outputId": "a956cf1b-b7f2-4e10-9034-4ac355fdc6df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 4. Lemmatization\n",
        "# Another normalization method is lemmatization. \n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "wnl = WordNetLemmatizer()\n",
        "[wnl.lemmatize(word) for word, dist in dist.most_common(20)]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.',\n",
              " 'is',\n",
              " 'better',\n",
              " 'than',\n",
              " 'to',\n",
              " 'the',\n",
              " ',',\n",
              " 'of',\n",
              " 'Although',\n",
              " 'never',\n",
              " 'be',\n",
              " 'one',\n",
              " '--',\n",
              " 'it',\n",
              " 'idea',\n",
              " 'are',\n",
              " 'should',\n",
              " 'obvious',\n",
              " 'way',\n",
              " 'do']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHH404S0gpOh",
        "outputId": "0c57dfc1-4fbd-4a8c-b777-62dc833d0dd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "wnl.lemmatize(\"corpora\"), wnl.lemmatize(\"stemming\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('corpus', 'stemming')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZVn7nDHiFAT",
        "outputId": "19e529af-4445-44e6-accd-2269fec13f1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Russian libarary for lemmatization pymorphy2\n",
        "!pip install pymorphy2"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.4MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0tjLoXTiilL"
      },
      "source": [
        "from pymorphy2 import MorphAnalyzer"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f7HMXXIioR7",
        "outputId": "94623f25-89e6-4cd0-9923-6431137d9e35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "morph = MorphAnalyzer()\n",
        "\n",
        "morph.parse(next(tokenize(russian_text)).text)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parse(word='граф', tag=OpencorporaTag('NOUN,anim,masc sing,nomn'), normal_form='граф', score=0.846153, methods_stack=((DictionaryAnalyzer(), 'граф', 52, 0),)),\n",
              " Parse(word='граф', tag=OpencorporaTag('NOUN,inan,masc sing,nomn'), normal_form='граф', score=0.076923, methods_stack=((DictionaryAnalyzer(), 'граф', 34, 0),)),\n",
              " Parse(word='граф', tag=OpencorporaTag('NOUN,inan,masc sing,accs'), normal_form='граф', score=0.038461, methods_stack=((DictionaryAnalyzer(), 'граф', 34, 3),)),\n",
              " Parse(word='граф', tag=OpencorporaTag('NOUN,inan,femn plur,gent'), normal_form='графа', score=0.038461, methods_stack=((DictionaryAnalyzer(), 'граф', 55, 8),))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM7GZ4Jqiypc",
        "outputId": "2f12e37e-2b2c-4a2c-af3b-416b80a5a525",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "morph.parse(\"мыслителей\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parse(word='мыслителей', tag=OpencorporaTag('NOUN,anim,masc plur,gent'), normal_form='мыслитель', score=0.8, methods_stack=((DictionaryAnalyzer(), 'мыслителей', 123, 7),)),\n",
              " Parse(word='мыслителей', tag=OpencorporaTag('NOUN,anim,masc plur,accs'), normal_form='мыслитель', score=0.2, methods_stack=((DictionaryAnalyzer(), 'мыслителей', 123, 9),))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    }
  ]
}